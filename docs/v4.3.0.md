# Release Version 4.3.0

The Release Version 4.3.0 includes new features, improvements, and bug fixes.

## Feature Updates

### SkyPoint Dataflow:

**Imports:**

- **Datetime format for ADLS Gen2** – Added Datetime in DD-MM-YYYY format for ADLS Gen2 connector.
- **Run History** - Run history for Dataflow imports is now available for the last three runs.

**Exports:**

- **Update success/failure numbers in exports** – The user can see the number of success and failure records in Export History.
- **Notification for missing Key-Value pair** - When a user leaves the Key or Value fields empty and clicks the "+" icon, a warning message appears to enter information.
> :grey_exclamation: **Note**: The system allows only 10 Key-Value pairs. The "+" icon is not visible at the 10th Key-Value pair.
- **Real-time status updates for the Exports** - Users can see the status getting updated as per the actions taken, which was slow earlier.


### SkyPoint Lakehouse:

- **Fluent table** - The fluent table in Databases is fixed to group and sort within groups. Groups also get sorted in ascending or descending order.
- **Remove manual provisioning of Lakehouse SQL** - Lakehouse SQL auto-provisioning starts at the Instance creation, and the user can see the status of success or failure under SQL access. Lakehouse SQL enabling screen is removed and disable button in the SQL Access screen is not visible to a user.

### SkyPoint Resolve:

- **Match confidence and data completeness for ML match** – Match confidence and data completeness show exact values on hover on the slider to select the precision for confidence and data completeness.

### SkyPoint Activate:  

**Audience:**  

- **Real-time status updates for the Audience** – Once the Audience is integrated and deployed, system will push the message for UI to process and display the real-time status.  
- **Logs standardization** - Logs standardization for Metrics added. Now the Run history has all the details related to a step performed by the system. Log Standardization API changes made for Audience > Run history.  
- **Run History** - Run history for the Audience shows all the states involved in running an Audience. Users can see the detailed view of the time taken in each step and process details for better debugging.  

**Metrics:**

- **Sorting for Metrics** – Sorting functionality is enabled on the Metrics page to sort and view the Metrics in different groups such as Display name, Type, etc.

### SkyPoint Predict:

- **Real-time status updates for Prediction models** – Once the prediction is integrated and deployed, system will push the message for UI to process and display the real-time status.
- **Run History** – Predict models will show all run history (Started, Model building, Completed).
- **Sentiment analysis** - Reputation management is done for users using a sentiment model and data from Google reviews. Now, users can see the overall sentiment of the reviewers on the SkyPoint Platform. 

### SkyPoint Empower:

- **Email Notification to Sender for every new DSR** – When the user creates a Data Subject Request (DSR), an email will be sent to the user's email with detailed information.  
- **Bulk Processing of DSR** - Users can Accept/Reject Multiple DSRs at a time through the checkbox. It saves a lot of manual effort. Auto rejection email is sent to the end-customers in case the email is not verified within 24 hours. This avoids piling up a lot of requests on the DSR page which are pending email verification.
> :grey_exclamation: **Note**: The user can select the multiple DSR request which has the email verified as "Yes". DSR with an email verified as "No" will be greyed out.
- **Cancel DSR if the Email is not verified after re-verification** - If the email is not verified after resending the email verification request to the customer, cancel the DSR request. The cancelation reason is displayed in the Rejected/Canceled tab.


### Settings and Administration:

- **Data ingestion through Delta Live Tables (DLT)** - Created a Databricks notebook for data ingestion through DLT for Microsoft SQL connector. It uses a simple declarative approach to build reliable data pipelines and automatically manages your infrastructure at scale.
- **SFMC connector** - SFMC import connector has been optimized for performance improvements.  
- **Convert Pandas data frame into Spark data frames** - Pandas run operations on a single machine, whereas Spark runs on multiple machines. For machine learning applications such as prediction models, Spark processes operations many times faster than Pandas. The following models are converted into Spark data frames:
  - Customer Lifetime Value (CLV)
  - Audience suggestions
- **Removal of CDM dependency** - The CDM dependency is removed for the following connectors to improve pipeline performance and stability:
  - Dynamics 365 (import connector)
  - Clutch (import connector)
  - Point Click Care (import connector)
  - Google BigQuery (import connector)
  - Campaign Monitor (export connector)


